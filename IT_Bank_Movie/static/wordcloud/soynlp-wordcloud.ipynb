{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어처리 시작하기 - 전처리, 토큰화, 명사추출\n",
    "* soynlp(https://github.com/lovit/soynlp)로 토큰화하고 명사를 추출해 워드클라우드 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('foo1.csv', engine='python', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"김학의 동영상, 3월 초 경찰이 제공\"…시점·이유 규명해야\n",
       "1    위기 내몰린 청와대 ‘메신저’…‘엇나간 해명’까지 사퇴 여론\n",
       "Name: 제목, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_title = df['제목'][:2]\n",
    "sample_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    그런데 박지원 의원은 문제의 동영상을 지난 2013년 3월 초에 경찰에게 받아서 박...\n",
       "1    SUB_TITLE_STARTSUB_TITLE_END문재인 대통령의 ‘입’인 김의겸 ...\n",
       "Name: 본문, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_content = df['본문'][:2]\n",
    "sample_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자신의 관심사에 맞는 단어로 데이터를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r'.*(비행기|여행|언어|호텔).*'\n",
    "care = df[df['제목'].str.match(p) |\n",
    "           df['본문'].str.match(p, flags=re.MULTILINE)]\n",
    "care.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "care.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "care.tail()\n",
    "care.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.tokenizer import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokened_title = tokenizer.tokenize(sample_content)\n",
    "tokened_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 데이터 전처리 \n",
    "* 개행문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    # 개행문자 제거\n",
    "    text = re.sub('\\\\\\\\n', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time을 찍어주면 해당 코드를 실행할 때 걸리는 시간을 출력해 줍니다\n",
    "%time sentences = df['본문'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time tokens = sentences.apply(tokenizer.tokenize)\n",
    "tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_kr = ['하지만', '그리고', '그런데', '저는','제가',\n",
    "                '그럼', '이런', '저런', '합니다',\n",
    "                '많은', '많이', '정말', '너무','[',']','것으로','했습니다','했다'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 워드클라우드 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def displayWordCloud(data = None, backgroundcolor = 'white', width=800, height=600 ):\n",
    "    wordcloud = WordCloud(\n",
    "                        font_path = '/Library/Fonts/NanumBarunGothic.ttf', \n",
    "                        stopwords = stopwords_kr,\n",
    "                        background_color = backgroundcolor, \n",
    "                        width = width, height = height).generate(data)\n",
    "    plt.figure(figsize = (15 , 10))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 출력해 보면 불용어(STOPWORD)가 너무 많습니다.\n",
    "%time displayWordCloud(' '.join(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.noun import LRNounExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "noun_extractor = LRNounExtractor(verbose=True)\n",
    "noun_extractor.train(sentences)\n",
    "nouns = noun_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출된 명사를 찍어봅니다.\n",
    "%time displayWordCloud(' '.join(nouns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특정 이미지 형태로 워드 클라우드 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일위에 출력하기\n",
    "from PIL import Image\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('apple.png')\n",
    "img_array=numpy.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud( font_path = '/Library/Fonts/NanumBarunGothic.ttf', \n",
    "                       stopwords = stopwords_kr,\n",
    "                       background_color = 'white', \n",
    "                       mask=img_array,\n",
    "                       width = 800, height = 600).generate(' '.join(nouns))\n",
    "plt.figure(figsize = (15 , 10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()  \n",
    "wordcloud.to_file(\"simple.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
